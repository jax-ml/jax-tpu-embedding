{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oudeZO61GTSL"
      },
      "source": [
        "## Using Jax TPUEmbedding (Single Host Pmap)\n",
        "\n",
        "This colab is to demonstrate how to use jax_tpu_embedding for training large embeddings in Jax.\n",
        "This example uses embedding lookup activation results as input, and trains on target.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 7413,
          "status": "ok",
          "timestamp": 1667016826069,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "RfCN_4yAlu2C"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "import functools\n",
        "from typing import Dict, Union\n",
        "\n",
        "from flax.training import common_utils\n",
        "from flax.training.train_state import TrainState\n",
        "import jax\n",
        "from jax.experimental import jax2tf\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "\n",
        "from jax_tpu_embedding import input_utils\n",
        "from jax_tpu_embedding import tpu_embedding_utils\n",
        "from jax_tpu_embedding import tpu_embedding as jte\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N__o1RDmFq0r"
      },
      "source": [
        "#### 0. Initialize TPU system for jax_tpu_embedding prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc7iuHml8fiY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 6620,
          "status": "ok",
          "timestamp": 1667016832832,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "yiOwIvnpaMX8"
      },
      "outputs": [],
      "source": [
        "# Note: TPUEmbedding user needs to call init_tpu_system in the beginning of program.\n",
        "tpu_embedding_utils.init_tpu_system()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ccDHzgpdS8"
      },
      "source": [
        "#### 1. Define Example Dense Model\n",
        "\n",
        "Dense model on TPU device is a simple MLP layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1667016833032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "VuGUlugqma4j"
      },
      "outputs": [],
      "source": [
        "import flax.linen as nn\n",
        "\n",
        "Array = Union[jnp.ndarray, jnp.DeviceArray]\n",
        "Initializer = jax.nn.initializers.Initializer\n",
        "\n",
        "class MLPLayers(nn.Module):\n",
        "  \"\"\"Create mlp layers.\"\"\"\n",
        "  hidden_dim: int\n",
        "  num_hidden_layers: int\n",
        "  dropout: float\n",
        "  num_classes: int\n",
        "  kernel_init: Initializer = nn.initializers.glorot_uniform()\n",
        "  bias_init: Initializer = nn.initializers.zeros\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x: Array, is_training: bool = False) -\u003e Array:\n",
        "    for _ in range(self.num_hidden_layers):\n",
        "      x = nn.Dense(\n",
        "          features=self.hidden_dim,\n",
        "          kernel_init=self.kernel_init,\n",
        "          bias_init=self.bias_init)(\n",
        "              x)\n",
        "      x = nn.relu(x)\n",
        "\n",
        "    if is_training:\n",
        "      x = nn.Dropout(rate=self.dropout)(x, deterministic=False)\n",
        "    x = nn.Dense(features=self.num_classes, bias_init=self.bias_init)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe-7bc85HoXF"
      },
      "source": [
        "##### Define one hot targets conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1667016833223,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "dQPm2f0OHnRC"
      },
      "outputs": [],
      "source": [
        "def compute_one_hot_targets(targets: Array, num_classes: int,\n",
        "                            on_value: float) -\u003e Array:\n",
        "  \"\"\"Compute one hot encoded targets.\n",
        "\n",
        "  Args:\n",
        "    targets: An array of target value.\n",
        "    num_classes: number of classes to one-hot encoding.\n",
        "    on_value: Value to fill to non-zero locations.\n",
        "  Returns:\n",
        "    An array of one-hot encoded targets.\n",
        "  \"\"\"\n",
        "  one_hot_targets = common_utils.onehot(targets, num_classes, on_value=on_value)\n",
        "  one_hot_targets = jax.tree_util.tree_map(lambda x: jnp.sum(x, axis=1),\n",
        "                                           one_hot_targets)\n",
        "  return one_hot_targets\n",
        "\n",
        "\n",
        "@jax.vmap\n",
        "def categorical_cross_entropy_loss(logits: Array, one_hot_targets: Array):\n",
        "  return -jnp.sum(one_hot_targets * nn.log_softmax(logits), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpEEgJ-58FM6"
      },
      "source": [
        "#### 2. Create dummy sample inputs\n",
        "\n",
        "We have two `watches` and `watches_targets` in dummy inputs.\n",
        "* Dense model takes embedding lookup results of `watches` and use `watches_targets` one hot target to train model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 54,
          "status": "ok",
          "timestamp": 1667016833454,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "lgONTxrb7-vO"
      },
      "outputs": [],
      "source": [
        "NUM_TARGET_IDS = 5\n",
        "NUM_WATCHES = 10\n",
        "\n",
        "def dummy_dataset(global_batch_size: int, vocab_size: int, num_classes: int, seed: int =123):\n",
        "  rng_state = np.random.RandomState(seed=seed)\n",
        "\n",
        "  def _create_feature():\n",
        "    watches = rng_state.randint(low=0, high=vocab_size,\n",
        "                                size=NUM_WATCHES * global_batch_size)\n",
        "    watches = tf.sparse.from_dense(watches.reshape(\n",
        "        [global_batch_size, NUM_WATCHES]))\n",
        "    targets = rng_state.randint(low=0, high=num_classes,\n",
        "                                size=NUM_TARGET_IDS * global_batch_size)\n",
        "    targets = tf.convert_to_tensor(\n",
        "        targets.reshape([global_batch_size, NUM_TARGET_IDS]))\n",
        "    return ({\n",
        "        'watches': tf.sparse.reset_shape(\n",
        "            watches, new_shape=[global_batch_size, vocab_size]),\n",
        "    }, {\n",
        "        'watches_target': tf.cast(targets, dtype=tf.float32),\n",
        "    })\n",
        "  ds = tf.data.Dataset.from_tensors(_create_feature())\n",
        "  ds = ds.repeat()\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipWYTskT7_OM"
      },
      "source": [
        "#### 3. Create Embedding Layer\n",
        "\n",
        "User needs to define feature configuration, it requires:\n",
        "* table to lookup for given feature.\n",
        "* output_shape (go/bc-enqueue-op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni73vLW_DHkW"
      },
      "source": [
        "##### Function to build feature configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "executionInfo": {
          "elapsed": 55,
          "status": "ok",
          "timestamp": 1667016833689,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "xe2NCvCz_AiW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def build_embedding_configs(batch_size_per_device: int,\n",
        "                            embedding_dimension: int,\n",
        "                            vocab_size: int):\n",
        "  \"\"\"Create feature configurations for YT5's embedding layer.\n",
        "\n",
        "  Args:\n",
        "    batch_size_per_device: batch size of inputs to equeue.\n",
        "    embedding_dimension: dimension size of embedding table.\n",
        "    vocab_size: vocabulary size of embedding table.\n",
        "  Returns:\n",
        "    A dictionary of feature configurations.\n",
        "  \"\"\"\n",
        "  feature_configs = {\n",
        "      'watches': tf.tpu.experimental.embedding.FeatureConfig(\n",
        "          table=tf.tpu.experimental.embedding.TableConfig(\n",
        "              vocabulary_size=vocab_size,\n",
        "              dim=embedding_dimension,\n",
        "              initializer=tf.initializers.TruncatedNormal(\n",
        "                  mean=0.0, stddev=1 / math.sqrt(embedding_dimension)),\n",
        "                  combiner='mean'),\n",
        "          output_shape=[batch_size_per_device])\n",
        "  }\n",
        "  return feature_configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDEAhHS04tuf"
      },
      "source": [
        "##### Setup flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1667016833874,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "cxziCaCc4sCz"
      },
      "outputs": [],
      "source": [
        "flags = dict(\n",
        "    global_batch_size=16,\n",
        "    embedding_dimension=4,\n",
        "    hidden_layer_dimension=8,\n",
        "    num_hidden_layers=1,\n",
        "    vocab_size=16,\n",
        "    num_classes=4,\n",
        "    learning_rate=1.0,\n",
        "    dropout=0.5,\n",
        "    num_targets=NUM_TARGET_IDS,\n",
        "    is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTt4SRuSatZ5"
      },
      "source": [
        "##### Create and Initialize A TPUEmbedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1667016834058,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "igFzVkVEhk2H"
      },
      "outputs": [],
      "source": [
        "batch_size_per_device = flags['global_batch_size'] // jax.device_count()\n",
        "\n",
        "feature_configs = build_embedding_configs(\n",
        "      batch_size_per_device=batch_size_per_device,\n",
        "      embedding_dimension=flags['embedding_dimension'],\n",
        "      vocab_size=flags['vocab_size'],\n",
        "      )\n",
        "\n",
        "embedding_optimizer = tf.tpu.experimental.embedding.Adagrad(\n",
        "    learning_rate=flags['learning_rate'])\n",
        "tpu_embedding_layer = jte.TPUEmbedding(\n",
        "    feature_configs=feature_configs, optimizer=embedding_optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "executionInfo": {
          "elapsed": 612,
          "status": "ok",
          "timestamp": 1667016834847,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "8dZrzdvv2LTR"
      },
      "outputs": [],
      "source": [
        "# Must call initialize_tpu_embedding to configure TPUEmbedding\n",
        "tpu_embedding_layer.initialize_tpu_embedding()\n",
        "\n",
        "# Call load_embedding_tables to initialize embedding tables.\n",
        "tpu_embedding_layer.load_embedding_tables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtapktjMIQvH"
      },
      "source": [
        "#### Input pipeline\n",
        "\n",
        "We have two inputs `watches` and `watches_targets`. User may want to use data parallelism aligns TensorCores.\n",
        "\n",
        "For this example, `watches` is input data to enqueue on CPU to be processed by\n",
        "TPUEmbedding hostsoftware. `watches_targets` is input data to TensorCore for dense\n",
        "model.\n",
        "\n",
        "Therefore we split input data for host and devices by `split_and_prefetch_to_host_and_devices`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1667016835081,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "S0H1UgJRkvoq"
      },
      "outputs": [],
      "source": [
        "ds = dummy_dataset(global_batch_size=flags['global_batch_size'],\n",
        "                   vocab_size=flags['vocab_size'],\n",
        "                   num_classes=flags['num_classes'])\n",
        "\n",
        "dummy_iter = input_utils.split_and_prefetch_to_host_and_devices(\n",
        "    iterator=iter(ds),\n",
        "    split_fn=lambda xs: {'host': xs[0], 'device': xs[1]},\n",
        "    host_input_fn=input_utils.enqueue_prefetch(\n",
        "        enqueue_fn=functools.partial(\n",
        "            tpu_embedding_layer.enqueue, is_training=flags['is_training'])),\n",
        "    device_input_fn=input_utils.make_pmap_array_fn(),\n",
        "    buffer_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8d-fcEENX32"
      },
      "source": [
        "#### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "executionInfo": {
          "elapsed": 1406,
          "status": "ok",
          "timestamp": 1667016836624,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "ksViIauGNXJ4"
      },
      "outputs": [],
      "source": [
        "# Create TrainState\n",
        "mlp_model = MLPLayers(\n",
        "    hidden_dim=flags['hidden_layer_dimension'],\n",
        "    num_hidden_layers=flags['num_hidden_layers'],\n",
        "    dropout=flags['dropout'],\n",
        "    num_classes=flags['num_classes'])\n",
        "\n",
        "init_params = mlp_model.init(\n",
        "    jax.random.PRNGKey(123),\n",
        "    jnp.ones((batch_size_per_device, flags['embedding_dimension'])))\n",
        "tx = optax.adagrad(learning_rate=flags['learning_rate'])\n",
        "\n",
        "train_state = TrainState.create(apply_fn=mlp_model.apply, params=init_params,\n",
        "                                tx=tx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjPPnD74T1P2"
      },
      "source": [
        "##### Build Train/Eval Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "executionInfo": {
          "elapsed": 55,
          "status": "ok",
          "timestamp": 1667016836820,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "BUcAct2GYC64"
      },
      "outputs": [],
      "source": [
        "def build_step(embedding_layer: jte.TPUEmbedding,\n",
        "               train_state: TrainState,\n",
        "               config_flags: Dict[str, Union[int, float]],\n",
        "               is_training: bool,\n",
        "               use_pjit: bool):\n",
        "  \"\"\"Build train or eval step using tpu embedding.\"\"\"\n",
        "\n",
        "  def forward(inputs):\n",
        "    embedding_activations = inputs['embedding_actv']\n",
        "    params = inputs['params']\n",
        "    logits = train_state.apply_fn(params, embedding_activations['watches'])\n",
        "    one_hot_targets = compute_one_hot_targets(\n",
        "        inputs['watches_targets'],\n",
        "        num_classes=config_flags['num_classes'],\n",
        "        on_value=1.0 / config_flags['num_targets'])\n",
        "    loss = categorical_cross_entropy_loss(logits, one_hot_targets)\n",
        "    loss = jnp.sum(loss, axis=0) * (1.0 / config_flags['global_batch_size'])\n",
        "    return loss\n",
        "\n",
        "  def step_fn(train_state, watches_targets):\n",
        "    embedding_activation = embedding_layer.dequeue()\n",
        "    inputs = {\n",
        "        'embedding_actv': embedding_activation,\n",
        "        'params': train_state.params,\n",
        "        'watches_targets': watches_targets,\n",
        "    }\n",
        "    if is_training:\n",
        "      loss, grads = jax.value_and_grad(forward)(inputs)\n",
        "      embedding_grads, params_grads = grads['embedding_actv'], grads['params']\n",
        "      if not use_pjit:\n",
        "          params_grads = jax.lax.pmean(params_grads, axis_name='devices')\n",
        "          loss = jax.lax.pmean(loss, axis_name='devices')\n",
        "      train_state = train_state.apply_gradients(grads=params_grads)\n",
        "      embedding_layer.apply_gradients(embedding_grads)\n",
        "    else:\n",
        "      loss = forward(inputs)\n",
        "    return loss, train_state\n",
        "\n",
        "  return step_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "executionInfo": {
          "elapsed": 54,
          "status": "ok",
          "timestamp": 1667016837054,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "vnVlomgFcj5D"
      },
      "outputs": [],
      "source": [
        "train_step_fn = build_step(\n",
        "    embedding_layer=tpu_embedding_layer,\n",
        "    train_state=train_state,\n",
        "    config_flags=flags,\n",
        "    is_training=flags['is_training'],\n",
        "    use_pjit=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsXdqFKESoDE"
      },
      "source": [
        "##### Run with pmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1667016837238,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "nTZcuPY5TsPx"
      },
      "outputs": [],
      "source": [
        "# Replicated TrainState.\n",
        "replicated_train_state = jax.device_put_replicated(train_state,\n",
        "                                                   jax.local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "executionInfo": {
          "elapsed": 920,
          "status": "ok",
          "timestamp": 1667016838299,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "OY5UKpasdq_4",
        "outputId": "fa256853-c2b8-4ec7-b6c4-a065e5e81e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_step =  0 loss =  [0.34891546 0.34891546 0.34891546 0.34891546 0.34891546 0.34891546\n",
            " 0.34891546 0.34891546]\n",
            "train_step =  1 loss =  [0.34749943 0.34749943 0.34749943 0.34749943 0.34749943 0.34749943\n",
            " 0.34749943 0.34749943]\n",
            "train_step =  2 loss =  [0.34622425 0.34622425 0.34622425 0.34622425 0.34622425 0.34622425\n",
            " 0.34622425 0.34622425]\n",
            "train_step =  3 loss =  [0.3451719 0.3451719 0.3451719 0.3451719 0.3451719 0.3451719 0.3451719\n",
            " 0.3451719]\n",
            "train_step =  4 loss =  [0.34430784 0.34430784 0.34430784 0.34430784 0.34430784 0.34430784\n",
            " 0.34430784 0.34430784]\n",
            "train_step =  5 loss =  [0.3435984 0.3435984 0.3435984 0.3435984 0.3435984 0.3435984 0.3435984\n",
            " 0.3435984]\n",
            "train_step =  6 loss =  [0.3429523 0.3429523 0.3429523 0.3429523 0.3429523 0.3429523 0.3429523\n",
            " 0.3429523]\n",
            "train_step =  7 loss =  [0.3423231 0.3423231 0.3423231 0.3423231 0.3423231 0.3423231 0.3423231\n",
            " 0.3423231]\n",
            "train_step =  8 loss =  [0.34173667 0.34173667 0.34173667 0.34173667 0.34173667 0.34173667\n",
            " 0.34173667 0.34173667]\n",
            "train_step =  9 loss =  [0.34122208 0.34122208 0.34122208 0.34122208 0.34122208 0.34122208\n",
            " 0.34122208 0.34122208]\n"
          ]
        }
      ],
      "source": [
        "num_steps = 10\n",
        "\n",
        "pmap_step_fn = jax.pmap(train_step_fn, axis_name='devices')\n",
        "for step in range(num_steps):\n",
        "  inputs = next(dummy_iter)\n",
        "  loss, replicated_train_state = pmap_step_fn(\n",
        "      replicated_train_state,\n",
        "      watches_targets=inputs['device']['watches_target'])\n",
        "  print('train_step = ', step, 'loss = ', loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/brain/experimental/jax_tpu_embedding/examples/colab:colab_binary",
        "kind": "private"
      },
      "name": "jax_tpu_embedding_singlehost_pmap.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
